{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader ,DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading API keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extarct the data from PDF\n",
    "def load_pdf(data_dir):\n",
    "    loader =DirectoryLoader(data_dir,\n",
    "                            glob = \"*.pdf\",\n",
    "                            loader_cls =PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(r\"C:\\github\\openai\\athina-ai\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating textn chunks \n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 50000,\n",
    "        chunk_overlap = 0\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs =docs[1:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "def download_hugging_face_embdinds():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embdinds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m OPENAI_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OPENAI_API_KEY\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfadc0225b44cb79996d6c2e5441e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 95, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\asyncio\\base_events.py\", line 641, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 83, in _aresults\n",
      "    raise e\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 78, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\asyncio\\tasks.py\", line 575, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\testset\\extractor.py\", line 49, in extract\n",
      "    results = await self.llm.generate(prompt=prompt, is_async=is_async)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 142, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 58, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 110, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 78, in inner\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\__init__.py\", line 410, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\__init__.py\", line 183, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\concurrent\\futures\\_base.py\", line 438, in result\n",
      "    return self.__get_result()\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\concurrent\\futures\\_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 61, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 569, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 657, in _agenerate\n",
      "    response = await self.async_client.create(messages=message_dicts, **params)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1214, in create\n",
      "    return await self._post(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1790, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1493, in request\n",
      "    return await self._request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1569, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1615, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1569, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1615, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1584, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtestset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevolutions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple, reasoning, multi_context\n\u001b[0;32m      4\u001b[0m generator \u001b[38;5;241m=\u001b[39m TestsetGenerator\u001b[38;5;241m.\u001b[39mfrom_langchain(\n\u001b[0;32m      5\u001b[0m     generator_llm,\n\u001b[0;32m      6\u001b[0m     critic_llm,\n\u001b[0;32m      7\u001b[0m     embeddings\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43msimple\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_context\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\testset\\generator.py:206\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[1;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[0;32m    204\u001b[0m distributions \u001b[38;5;241m=\u001b[39m distributions \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mDocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_langchain_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    211\u001b[0m     test_size\u001b[38;5;241m=\u001b[39mtest_size,\n\u001b[0;32m    212\u001b[0m     distributions\u001b[38;5;241m=\u001b[39mdistributions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[0;32m    217\u001b[0m )\n",
      "File \u001b[1;32mc:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\testset\\docstore.py:215\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_documents\u001b[1;34m(self, docs, show_progress)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# split documents with self.splitter into smaller nodes\u001b[39;00m\n\u001b[0;32m    211\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    212\u001b[0m     Node\u001b[38;5;241m.\u001b[39mfrom_langchain_document(d)\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39mtransform_documents(docs)\n\u001b[0;32m    214\u001b[0m ]\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\testset\\docstore.py:254\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_nodes\u001b[1;34m(self, nodes, show_progress)\u001b[0m\n\u001b[0;32m    252\u001b[0m results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nodes_to_embed\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead."
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "testset = generator.generate_with_langchain_docs(docs, test_size=30, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtestset\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testset' is not defined"
     ]
    }
   ],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import pinecone\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"policybot\"\n",
    "# Connect to Pinecone index \n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genration part\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "You are an a professional AI assistant for car insurance inquiries, \\\n",
    "use the provided information to accurately address the user's question. \\\n",
    "If the answer is not available, clearly state that you do not have the information instead of providing a speculative response.\n",
    "-----------------------------\n",
    "Context: {context}\n",
    "-----------------------------\n",
    "Question: {question}\n",
    "\n",
    "Please provide in professional and helpful answer below , without any additional commentary.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = CohereRerank(cohere_api_key=\"nbDqU1hTVxWmXGbLYI6OnYhp4Cx40MZ5hOmO5oKX\")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"context\":  compression_retriever,\n",
    "        \"question\":  RunnablePassthrough(),\n",
    "    }\n",
    "    | PROMPT\n",
    "    | llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"qa_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"answer\": \"ground_truth\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What type of policy is Comprehensive with Driv...</td>\n",
       "      <td>Same as a Comprehensive policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the deductible for collision coverage?</td>\n",
       "      <td>$500.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Excess in the context of car insurance?</td>\n",
       "      <td>The amount that you may have to pay towards a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Am I covered if I leave my car unlocked or the...</td>\n",
       "      <td>No, we won’t pay a claim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where can I find the exact meanings of specifi...</td>\n",
       "      <td>Glossary on page 4 or at the start of each sec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What type of policy is Comprehensive with Driv...   \n",
       "1     What is the deductible for collision coverage?   \n",
       "2    What is Excess in the context of car insurance?   \n",
       "3  Am I covered if I leave my car unlocked or the...   \n",
       "4  Where can I find the exact meanings of specifi...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0                     Same as a Comprehensive policy  \n",
       "1                                              $500.  \n",
       "2  The amount that you may have to pay towards a ...  \n",
       "3                          No, we won’t pay a claim.  \n",
       "4  Glossary on page 4 or at the start of each sec...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"question\"].to_list()\n",
    "ground_truth = df[\"ground_truth\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What type of policy is Comprehensive with DriveSure?',\n",
       " 'What is the deductible for collision coverage?',\n",
       " 'What is Excess in the context of car insurance?',\n",
       " 'Am I covered if I leave my car unlocked or the keys in the car?',\n",
       " 'Where can I find the exact meanings of specific words and phrases?']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What type of policy is Comprehensive with DriveSure?\n",
      "incerted\n",
      "What is the deductible for collision coverage?\n",
      "incerted\n",
      "What is Excess in the context of car insurance?\n",
      "incerted\n",
      "Am I covered if I leave my car unlocked or the keys in the car?\n",
      "incerted\n",
      "Where can I find the exact meanings of specific words and phrases?\n",
      "incerted\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "data = {\"question\": [], \"answer\": [], \"contexts\": [], \"ground_truth\": ground_truth}\n",
    "\n",
    "for query in questions:\n",
    "    data[\"question\"].append(query)\n",
    "    data[\"answer\"].append(chain.invoke(query))\n",
    "    print(query)\n",
    "    data[\"contexts\"].append([doc.page_content for doc in compression_retriever.invoke(query)])\n",
    "    print(\"incerted\")\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(test_cases=[], goldens=[], conversational_goldens=[], _alias=None, _id=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c0a707e1b7467aa2b02ea690318ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 95, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\asyncio\\base_events.py\", line 641, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 83, in _aresults\n",
      "    raise e\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 78, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\asyncio\\tasks.py\", line 575, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 125, in ascore\n",
      "    raise e\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 121, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 169, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 142, in async_wrapped\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 58, in __call__\n",
      "    else:\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 110, in iter\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 78, in inner\n",
      "    await self.sleep(do)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\__init__.py\", line 410, in exc_check\n",
      "    return self.exception() is not None\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\__init__.py\", line 183, in reraise\n",
      "    else:\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\concurrent\\futures\\_base.py\", line 438, in result\n",
      "    return self.__get_result()\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\concurrent\\futures\\_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 61, in __call__\n",
      "    def __iter__(self) -> t.Generator[AttemptManager, None, None]:\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 569, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 657, in _agenerate\n",
      "    response = await self.async_client.create(messages=message_dicts, **params)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1214, in create\n",
      "    return await self._post(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1790, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1493, in request\n",
      "    return await self._request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1569, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1615, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1569, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1615, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"c:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\openai\\_base_client.py\", line 1584, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     faithfulness,\n\u001b[0;32m      4\u001b[0m     answer_relevancy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     context_precision,\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_relevancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_recall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\evaluation.py:250\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluation_group_cm\u001b[38;5;241m.\u001b[39mended:\n\u001b[0;32m    248\u001b[0m         evaluation_rm\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    252\u001b[0m     result \u001b[38;5;241m=\u001b[39m Result(\n\u001b[0;32m    253\u001b[0m         scores\u001b[38;5;241m=\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_list(scores),\n\u001b[0;32m    254\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m    255\u001b[0m         binary_columns\u001b[38;5;241m=\u001b[39mbinary_metrics,\n\u001b[0;32m    256\u001b[0m     )\n",
      "File \u001b[1;32mc:\\github\\openai\\athina-ai\\env\\lib\\site-packages\\ragas\\evaluation.py:232\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[0;32m    230\u001b[0m results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;241m==\u001b[39m []:\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# convert results to dataset_like\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n",
      "\u001b[1;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead."
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "df = result.to_pandas()\n",
    "\n",
    "heatmap_data = df[['context_relevancy', 'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']]\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('green_red', ['red', 'green'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", linewidths=.5, cmap=cmap)\n",
    "\n",
    "plt.yticks(ticks=range(len(df['question'])), labels=df['question'], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Your task is to write a factoid question and an answer given a context.\n",
    "Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n",
    "Your factoid question should be formulated in the same style as questions users could ask in a search engine.\n",
    "This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "------------\n",
    "{context}\n",
    "------------\n",
    "\n",
    "Create 5 Question and Answer pairs in JSON format.\n",
    "Make sure not to lose any important information.\n",
    "here is an example:\n",
    "\\\"question\\\": \\\"What is AI?\\\", \\\"answer\\\": \\\"AI stands for Artificial Intelligence.\\\", \\\n",
    "\\\"question\\\": \\\"What is ML?\\\", \\\"answer\\\": \\\"ML stands for Machine Learning.\\\", \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_QUESTIONS = PromptTemplate(template=prompt_template, input_variables=[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genration part\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from typing import List, Dict\n",
    "import re\n",
    "import json\n",
    "\n",
    "class dictOutput(BaseOutputParser):\n",
    "    def parse(self, text: str) -> List[Dict[str, str]]:\n",
    "        # Finding all JSON objects in the text\n",
    "        matches = re.findall(r'\\{[^}]+\\}', text)\n",
    "        \n",
    "        if not matches:\n",
    "            print(\"No JSON objects found in the input text.\")\n",
    "            return []\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        for json_text in matches:\n",
    "            try:\n",
    "                # Load the JSON data\n",
    "                data = json.loads(json_text)\n",
    "                \n",
    "                # Extract the question and answer\n",
    "                question = data.get(\"question\")\n",
    "                answer = data.get(\"answer\")\n",
    "                \n",
    "                if question is not None and answer is not None:\n",
    "                    result.append({\n",
    "                        \"question\": question,\n",
    "                        \"answer\": answer\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Invalid JSON object found: missing 'question' or 'answer' key in {json_text}\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Invalid JSON format found in text: {json_text}\")\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain for generating question and answer\n",
    "chain_for_qa = PROMPT_QUESTIONS | llm | dictOutput()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'What are accessories in car insurance?', 'answer': 'Parts or products specifically designed to be fitted to your car, including electric car’s charging cables and the charger installed at your home.'}, {'question': 'What is an approved repairer in car insurance?', 'answer': 'A repairer in our network of contracted repairers who’s approved by us to carry out repairs to your car following a claim under this policy.'}, {'question': 'What is an automated car in the context of car insurance?', 'answer': 'A car that is lawfully driving itself on roads or other public places in Great Britain.'}, {'question': 'What is a certificate of motor insurance?', 'answer': 'A document that provides evidence that you have taken out the insurance you must have by law.'}, {'question': 'What is excess in car insurance?', 'answer': 'The amount that you may have to pay towards a claim.'}]\n"
     ]
    }
   ],
   "source": [
    "    print(chain_for_qa.invoke(docs[2].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the limit of 13 requests per minute. Waiting for the next minute...\n",
      "Reached the limit of 13 requests per minute. Waiting for the next minute...\n",
      "Reached the limit of 13 requests per minute. Waiting for the next minute...\n",
      "Question-answer pairs have been saved to qa_pairs.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "# Assuming `docs` is a list of documents and each document has a `page_content` attribute\n",
    "# Also assuming `chain_for_qa` is an object with an `invoke` method that processes the content\n",
    "\n",
    "# List to hold all question-answer pairs\n",
    "qa_pairs_list = []\n",
    "\n",
    "# Maximum number of requests per minute\n",
    "max_requests_per_minute = 13\n",
    "# Time interval between requests in seconds\n",
    "interval = 60 / max_requests_per_minute\n",
    "\n",
    "# Loop through each document and process its content\n",
    "for index, doc in enumerate(docs):\n",
    "    # Get the page content\n",
    "    page_content = doc.page_content\n",
    "    \n",
    "    # Invoke the chain to get question-answer pairs\n",
    "    qa_pairs = chain_for_qa.invoke(page_content)\n",
    "    \n",
    "    # Assuming the output of `invoke` is a list of question-answer pairs\n",
    "    qa_pairs_list.extend(qa_pairs)\n",
    "    \n",
    "    # Wait to respect the rate limit, except after the last request\n",
    "    if (index + 1) % max_requests_per_minute == 0:\n",
    "        print(\"Reached the limit of 13 requests per minute. Waiting for the next minute...\")\n",
    "        time.sleep(60)  # Wait for a minute before making more requests\n",
    "    else:\n",
    "        time.sleep(interval)  # Wait for the calculated interval before the next request\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_file_name = 'qa_pairs.csv'\n",
    "\n",
    "# Save the collected question-answer pairs to a CSV file\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    fieldnames = ['question', 'answer']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for qa in qa_pairs_list:\n",
    "        writer.writerow(qa)\n",
    "\n",
    "print(f\"Question-answer pairs have been saved to {csv_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"qa_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the policy period?</td>\n",
       "      <td>12 months from the effective date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the deductible for collision coverage?</td>\n",
       "      <td>$500.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the limit for personal liability?</td>\n",
       "      <td>$100,000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is roadside assistance included?</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the process for filing a claim?</td>\n",
       "      <td>Call 1-800-CLAIMS or report online within 24 h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "0                      What is the policy period?   \n",
       "1  What is the deductible for collision coverage?   \n",
       "2       What is the limit for personal liability?   \n",
       "3                Is roadside assistance included?   \n",
       "4         What is the process for filing a claim?   \n",
       "\n",
       "                                              answer  \n",
       "0                 12 months from the effective date.  \n",
       "1                                              $500.  \n",
       "2                                          $100,000.  \n",
       "3                                               Yes.  \n",
       "4  Call 1-800-CLAIMS or report online within 24 h...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens if I choose to repair my car at a...</td>\n",
       "      <td>Those repairs will NOT be guaranteed by the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where can I find the exact meanings of specifi...</td>\n",
       "      <td>Glossary on page 4 or at the start of each sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a Certificate of motor insurance?</td>\n",
       "      <td>A document that provides evidence that you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What makes up the policy?</td>\n",
       "      <td>This booklet, car insurance details, certifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What if I arrange windscreen repairs or replac...</td>\n",
       "      <td>The insurer will only cover a limited amount.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is a Courtesy car?</td>\n",
       "      <td>A small hatchback car, or similar car, that an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the limit for replacing a child car seat?</td>\n",
       "      <td>Unlimited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the excess for accidental damage claim...</td>\n",
       "      <td>£250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In what situations do I not need to pay an exc...</td>\n",
       "      <td>If you're in an accident that's not your fault...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Who is the 'Policyholder'?</td>\n",
       "      <td>The person named as the policyholder on the ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How much is covered for removable electronic e...</td>\n",
       "      <td>£500 (Essentials), £1,000 (Comprehensive), £2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Am I covered if I leave my car unlocked or the...</td>\n",
       "      <td>No, we won’t pay a claim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is DriveSure?</td>\n",
       "      <td>Our telematics insurance product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is included in the policy if I have Green...</td>\n",
       "      <td>Breakdown cover and car insurance as part of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What is the limit for personal liability?</td>\n",
       "      <td>$100,000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What information do I need to provide when mak...</td>\n",
       "      <td>Personal details, policy number, car registrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How many claims are allowed in 3 years for Pro...</td>\n",
       "      <td>2 claims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How much is covered for removable electronic e...</td>\n",
       "      <td>£1,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What is considered a 'Loss of any limb'?</td>\n",
       "      <td>A limb severed at or above the wrist or ankle,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the policy period?</td>\n",
       "      <td>12 months from the effective date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How much is covered for medical expenses?</td>\n",
       "      <td>£200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What are 'Modifications' to a car?</td>\n",
       "      <td>Any changes to the car's standard specificatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What should I do if I receive any communicatio...</td>\n",
       "      <td>Contact the insurance company straight away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is the phone number to call for windscree...</td>\n",
       "      <td>0800 328 9150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What is the total travel cost limit for Guaran...</td>\n",
       "      <td>£500 per claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What happens if my car is written off and we a...</td>\n",
       "      <td>The insurer will have met their responsibiliti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Is roadside assistance included?</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Who is covered to drive other cars?</td>\n",
       "      <td>Check your certificate of motor insurance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What is the process for filing a claim?</td>\n",
       "      <td>Call 1-800-CLAIMS or report online within 24 h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What is covered if my car needs to be taken to...</td>\n",
       "      <td>Reasonable costs to take the car to the neares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What is the overall limit for all claims, incl...</td>\n",
       "      <td>£100,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What should I do with all these documents?</td>\n",
       "      <td>Read them carefully and keep them safe in case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What is the limit of liability for injuries to...</td>\n",
       "      <td>Unlimited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Are my electric car’s charging cables covered?</td>\n",
       "      <td>Yes, under ‘Section 2: Fire and theft’ or ‘Sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What is the limit of liability for property da...</td>\n",
       "      <td>£20,000,000 per accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What are Accessories in the context of car ins...</td>\n",
       "      <td>Parts or products specifically designed to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What is the 'Market value' of a car?</td>\n",
       "      <td>The cost of replacing the car with another of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Is the Uninsured Driver Promise included?</td>\n",
       "      <td>Included</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Do I need to inform the insurance company even...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What is Excess in the context of car insurance?</td>\n",
       "      <td>The amount that you may have to pay towards a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>What is the limit for personal belongings?</td>\n",
       "      <td>£250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>What is the duration of repair if you use a di...</td>\n",
       "      <td>21 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What is the deductible for collision coverage?</td>\n",
       "      <td>$500.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What is the daily travel cost limit for Guaran...</td>\n",
       "      <td>£50 per day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>What kind of parts may be used to repair my car?</td>\n",
       "      <td>Parts that haven’t been made by my car’s manuf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What type of policy is Comprehensive with Driv...</td>\n",
       "      <td>Same as a Comprehensive policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>How much will you pay if my car is damaged?</td>\n",
       "      <td>Up to its UK market value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Is a courtesy car included in the policy?</td>\n",
       "      <td>Yes, subject to availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Who is the 'Main driver'?</td>\n",
       "      <td>The person declared as the main user of the ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Who is an Approved repairer?</td>\n",
       "      <td>A repairer in our network of contracted repair...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What happens if I choose to repair my car at a...   \n",
       "1   Where can I find the exact meanings of specifi...   \n",
       "2           What is a Certificate of motor insurance?   \n",
       "3                           What makes up the policy?   \n",
       "4   What if I arrange windscreen repairs or replac...   \n",
       "5                             What is a Courtesy car?   \n",
       "6   What is the limit for replacing a child car seat?   \n",
       "7   What is the excess for accidental damage claim...   \n",
       "8   In what situations do I not need to pay an exc...   \n",
       "9                          Who is the 'Policyholder'?   \n",
       "10  How much is covered for removable electronic e...   \n",
       "11  Am I covered if I leave my car unlocked or the...   \n",
       "12                                 What is DriveSure?   \n",
       "13  What is included in the policy if I have Green...   \n",
       "14          What is the limit for personal liability?   \n",
       "15  What information do I need to provide when mak...   \n",
       "16  How many claims are allowed in 3 years for Pro...   \n",
       "17  How much is covered for removable electronic e...   \n",
       "18           What is considered a 'Loss of any limb'?   \n",
       "19                         What is the policy period?   \n",
       "20          How much is covered for medical expenses?   \n",
       "21                 What are 'Modifications' to a car?   \n",
       "22  What should I do if I receive any communicatio...   \n",
       "23  What is the phone number to call for windscree...   \n",
       "24  What is the total travel cost limit for Guaran...   \n",
       "25  What happens if my car is written off and we a...   \n",
       "26                   Is roadside assistance included?   \n",
       "27                Who is covered to drive other cars?   \n",
       "28            What is the process for filing a claim?   \n",
       "29  What is covered if my car needs to be taken to...   \n",
       "30  What is the overall limit for all claims, incl...   \n",
       "31         What should I do with all these documents?   \n",
       "32  What is the limit of liability for injuries to...   \n",
       "33     Are my electric car’s charging cables covered?   \n",
       "34  What is the limit of liability for property da...   \n",
       "35  What are Accessories in the context of car ins...   \n",
       "36               What is the 'Market value' of a car?   \n",
       "37          Is the Uninsured Driver Promise included?   \n",
       "38  Do I need to inform the insurance company even...   \n",
       "39    What is Excess in the context of car insurance?   \n",
       "40         What is the limit for personal belongings?   \n",
       "41  What is the duration of repair if you use a di...   \n",
       "42     What is the deductible for collision coverage?   \n",
       "43  What is the daily travel cost limit for Guaran...   \n",
       "44   What kind of parts may be used to repair my car?   \n",
       "45  What type of policy is Comprehensive with Driv...   \n",
       "46        How much will you pay if my car is damaged?   \n",
       "47          Is a courtesy car included in the policy?   \n",
       "48                          Who is the 'Main driver'?   \n",
       "49                       Who is an Approved repairer?   \n",
       "\n",
       "                                         ground_truth  \n",
       "0   Those repairs will NOT be guaranteed by the in...  \n",
       "1   Glossary on page 4 or at the start of each sec...  \n",
       "2   A document that provides evidence that you hav...  \n",
       "3   This booklet, car insurance details, certifica...  \n",
       "4       The insurer will only cover a limited amount.  \n",
       "5   A small hatchback car, or similar car, that an...  \n",
       "6                                           Unlimited  \n",
       "7                                                £250  \n",
       "8   If you're in an accident that's not your fault...  \n",
       "9   The person named as the policyholder on the ca...  \n",
       "10  £500 (Essentials), £1,000 (Comprehensive), £2,...  \n",
       "11                          No, we won’t pay a claim.  \n",
       "12                  Our telematics insurance product.  \n",
       "13  Breakdown cover and car insurance as part of t...  \n",
       "14                                          $100,000.  \n",
       "15  Personal details, policy number, car registrat...  \n",
       "16                                           2 claims  \n",
       "17                                             £1,000  \n",
       "18  A limb severed at or above the wrist or ankle,...  \n",
       "19                 12 months from the effective date.  \n",
       "20                                               £200  \n",
       "21  Any changes to the car's standard specificatio...  \n",
       "22        Contact the insurance company straight away  \n",
       "23                                      0800 328 9150  \n",
       "24                                     £500 per claim  \n",
       "25  The insurer will have met their responsibiliti...  \n",
       "26                                               Yes.  \n",
       "27         Check your certificate of motor insurance.  \n",
       "28  Call 1-800-CLAIMS or report online within 24 h...  \n",
       "29  Reasonable costs to take the car to the neares...  \n",
       "30                                           £100,000  \n",
       "31  Read them carefully and keep them safe in case...  \n",
       "32                                          Unlimited  \n",
       "33  Yes, under ‘Section 2: Fire and theft’ or ‘Sec...  \n",
       "34                           £20,000,000 per accident  \n",
       "35  Parts or products specifically designed to be ...  \n",
       "36  The cost of replacing the car with another of ...  \n",
       "37                                           Included  \n",
       "38                                                Yes  \n",
       "39  The amount that you may have to pay towards a ...  \n",
       "40                                               £250  \n",
       "41                                            21 days  \n",
       "42                                              $500.  \n",
       "43                                        £50 per day  \n",
       "44  Parts that haven’t been made by my car’s manuf...  \n",
       "45                     Same as a Comprehensive policy  \n",
       "46                         Up to its UK market value.  \n",
       "47                       Yes, subject to availability  \n",
       "48  The person declared as the main user of the ca...  \n",
       "49  A repairer in our network of contracted repair...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EvaluationDataset.__init__() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepeval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationDataset\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mEvaluationDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m dataset\u001b[38;5;241m.\u001b[39mgenerate_goldens_from_docs(\n\u001b[0;32m      5\u001b[0m     \n\u001b[0;32m      6\u001b[0m     document_paths\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mathina-ai\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpolicy-booklet-0923.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      7\u001b[0m     max_goldens_per_document\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: EvaluationDataset.__init__() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_case' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_customer_chatbot(\u001b[43mtest_case\u001b[49m, LLMTestCase)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_case' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(test_cases=[], goldens=[], conversational_goldens=[], _alias=None, _id=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.deepeval import DeepEvalEvaluator, DeepEvalMetric\n",
    "\n",
    "QUESTIONS = df[\"question\"]\n",
    "CONTEXTS = [\n",
    "    [\n",
    "        \"The popularity of sports can be measured in various ways, including TV viewership, social media presence, number of participants, and economic impact.\",\n",
    "        \"Football is undoubtedly the world's most popular sport with major events like the FIFA World Cup and sports personalities like Ronaldo and Messi, drawing a followership of more than 4 billion people.\",\n",
    "    ],\n",
    "    [\n",
    "        \"Python, created by Guido van Rossum in the late 1980s, is a high-level general-purpose programming language.\",\n",
    "        \"Its design philosophy emphasizes code readability, and its language constructs aim to help programmers write clear, logical code for both small and large-scale software projects.\",\n",
    "    ],\n",
    "]\n",
    "RESPONSES = [\n",
    "    \"Football is the most popular sport with around 4 billion followers worldwide\",\n",
    "    \"Python language was created by Guido van Rossum.\",\n",
    "]\n",
    "\n",
    "pipeline = Pipeline()\n",
    "evaluator = DeepEvalEvaluator(\n",
    "    metric=DeepEvalMetric.FAITHFULNESS,\n",
    "    metric_params={\"model\": \"gpt-4\"},\n",
    ")\n",
    "pipeline.add_component(\"evaluator\", evaluator)\n",
    "\n",
    "# Each metric expects a specific set of parameters as input. Refer to the\n",
    "# DeepEvalMetric class' documentation for more details.\n",
    "results = pipeline.run({\"evaluator\": {\"questions\": QUESTIONS, \"contexts\": CONTEXTS, \"responses\": RESPONSES}})\n",
    "\n",
    "for output in results[\"evaluator\"][\"results\"]:\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
